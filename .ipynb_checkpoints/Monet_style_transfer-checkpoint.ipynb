{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0bfac4",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0313db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fe06299",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6cba0",
   "metadata": {},
   "source": [
    "# Load image data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da62f21",
   "metadata": {},
   "source": [
    "## Dataset with transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895ecb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_normalize = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d505e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32bc6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = Subset(dset.ImageFolder(\"./dataset/gan-getting-started/monet/\", transform_normalize), range(150))\n",
    "content_data = Subset(dset.ImageFolder(\"./dataset/gan-getting-started/photo/\", transform_normalize), range(1))\n",
    "target_data = Subset(dset.ImageFolder(\"./dataset/gan-getting-started/photo/\", transform_tensor), range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c31ffb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n",
    "    image = (image - mean[:, None, None]) / std[:, None, None]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4830dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target_data[0][0].clone().requires_grad_(True)\n",
    "target = target.to(device)\n",
    "target = normalize_image(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c10529",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e700e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_loader = DataLoader(style_data)\n",
    "target_loader = DataLoader(target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e12f2e",
   "metadata": {},
   "source": [
    "# Load VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d12d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaydenpark\\Anaconda3\\envs\\nlp3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jaydenpark\\Anaconda3\\envs\\nlp3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "vgg = models.vgg19(pretrained=True).features.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2656dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(tensor):\n",
    "    # batch, channel, height, width\n",
    "    _, c, h, w = tensor.size()\n",
    "    # squeeze batch dimension and change shape of tensor to dense\n",
    "    tensor = tensor.view(c, h * w)\n",
    "    # matrix multiplication\n",
    "    # => channel by channel\n",
    "    gram = torch.mm(tensor, tensor.t())\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b57b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature of image using pre-trained model\n",
    "def get_style_features(style_loader, model):\n",
    "    layers = {\n",
    "        '0':'conv1_1',\n",
    "#         '5':'conv2_1',\n",
    "#         '10':'conv3_1',\n",
    "#         '19':'conv4_1',\n",
    "#         '28':'conv5_1',\n",
    "    }\n",
    "    style_features = {}\n",
    "    for i, (x, _) in enumerate(style_loader):\n",
    "        x = x.to(device)\n",
    "        style_features[f'style_{i}'] = {}\n",
    "        for name, layer in model._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in layers:\n",
    "                style_gram = gram_matrix(x)\n",
    "                style_features[f'style_{i}'][layers[name]] = style_gram\n",
    "    return style_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d73ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_features = get_style_features(style_loader, vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37eaf32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_features(target_loader, model):\n",
    "    layers = {\n",
    "        '0':'conv1_1',\n",
    "#         '5':'conv2_1',\n",
    "#         '10':'conv3_1',\n",
    "#         '19':'conv4_1',\n",
    "#         '28':'conv5_1',\n",
    "    }\n",
    "    target_features = {}\n",
    "    for i, (x, _) in enumerate(target_loader):\n",
    "        x = x.to(device)\n",
    "        target_features[f'target_{i}'] = {}\n",
    "        for name, layer in model._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in layers:\n",
    "                target_gram = gram_matrix(x)\n",
    "                target_features[f'target_{i}'][layers[name]] = target_gram\n",
    "    return target_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31787de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = get_style_features(target_loader, vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc81dde0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d085f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8be25cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3654686708.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [14]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in range(1000):\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    content_loss = torch.mean(target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297989a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
